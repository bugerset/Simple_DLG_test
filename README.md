# Simple_DLG_test (PyTorch)

A minimal PyTorch implementation of **Deep Leakage from Gradients (DLG)** on **MNIST** and **CIFAR-10**.
Given a clientâ€™s shared gradients (typically **batch size = 1**), this code reconstructs the input image and label by **gradient matching**.

> âš ï¸ This repo is for **research/educational** purposes only.

---

## Overview

DLG assumes an attacker (e.g., server) can access:
- the **global model parameters** used by the client, and
- the **client gradients** computed from a **single(or more) mini-batch** (batch size = 1 works best).

The attacker then optimizes dummy variables `(x', y')` such that:
`âˆ‡Î¸ L(fÎ¸(x'), y') â‰ˆ âˆ‡Î¸ L(fÎ¸(x), y)`.

---

## Threat Model (Assumptions)

- The attacker has access to the **global model architecture and weights** at the round of interest.
- The attacker can observe the **client gradients** from **one mini-batch** (default: **batch size = 1**).
- The attacker does **not** have access to the clientâ€™s raw data or labels.

---

## Method (DLG)

We optimize:
- `dummy_x` (image in pixel space, clamped to [0,1])
- `dummy_y` (label logits -> softmax)

by minimizing the gradient matching objective:
`Gradient_Distance = Î£ ||g_dummy - g_client||Â²`.

---

## Recommended Folder Structure

Your `main.py` imports modules like `data.cifar10`, `fl.fedavg`, etc.  
So the easiest way to run without changing code is to organize files like this:
```
â”œâ”€â”€ main.py
â”œâ”€â”€ attack/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ generator.py
â”‚   â””â”€â”€  noise.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cifar10.py
â”‚	â”œâ”€â”€ mnist.py
â”‚   â””â”€â”€ partition.py
â”œâ”€â”€ fl/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ fedavg.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ simplenet.py
â””â”€â”€ utils/
 	â”œâ”€â”€ __init__.py
	â”œâ”€â”€ plotting.py
 	â”œâ”€â”€ device.py
    â”œâ”€â”€ eval.py
    â”œâ”€â”€ parser.py
    â””â”€â”€ seed.py
```

---

## Requirements

- Python 3.9+ recommended
- PyTorch + torchvision
- numpy

Run with default settings:
```bash
python main.py
```
Examples: 
```bash
python main.py --data-set mnist --attack-iter 200
python main.py --data-set cifar10 --attack-iter 500
python main.py --data-set mnist --attack-iter 100 --grad-amp 1e4 --batch-size 8
```

## Device Selection

The code supports:
```
	â€¢	--device auto (default): selects CUDA if available, else MPS (Apple Silicon), else CPU
	â€¢	--device cuda
	â€¢	--device mps
	â€¢	--device cpu
```

Example:
```bash
python main.py --device auto
```

## CLI Arguments

Key arguments (from utils/parser.py):
```
	â€¢	Reproducibility / compute
		â€¢	--seed (default: 845)
		â€¢	--device in {auto,cpu,cuda,mps}

	â€¢	Training method
		â€¢	--dyn-alpha (FedDyn alpha, default 0.1)

	â€¢	Dataset
		â€¢   --data-set (default cifar10, choices=[cifar10, mnist])
		â€¢	--data-root (default ./data)
		â€¢	--augment / --no-augment
		â€¢	--normalize / --no-normalize
		â€¢	--test-batch-size (default 128)

	â€¢	Federated learning config
		â€¢	--num-clients (default 10)
		â€¢	--client-frac fraction of clients sampled per round (default 0.25)
		â€¢	--local-epochs (default 1)
		â€¢	--batch-size (default 100)
		â€¢	--lr learning rate (default 1e-2)
		â€¢	--rounds communication rounds (default 10)

	â€¢	Data partitioning
		â€¢	--partition in {iid,niid}
		â€¢	--alpha: Dirichlet concentration parameter controlling Non-IID severity.
		    	â”œâ”€â”€ Î± = 0.1 ~ 0.3: highly skewed label distribution (strong Non-IID)
		  		â”œâ”€â”€	Î± = 0.5: moderate Non-IID (default)
		  		â””â”€â”€	Î± = 0.8 ~ 1.0: closer to IID
		â€¢	--min-size minimum samples per client in non-IID (default 10)
		â€¢	--print-labels / --no-print-labels

	â€¢	Learning rate Scheduler (ReduceOnPlateau)
		â€¢	--lr-factor (learning rate * factor, default 0.5)
		â€¢	--lr-patience (default 5)
		â€¢	--min-lr (deafult 1e-6)
		â€¢	--lr-threshold (default 1e-4)
		â€¢	--lr-cooldown (default 0)
```
## FedDyn Implementation Notes

### 1) Client-side Update (fl/feddyn.py)

Each client minimizes a dynamically regularized objective to reduce client drift from the global optimum.

**Local objective (per client):**

$$ğ·_k^t = L_{total}(ğ·) - {\langle g_k^{t-1}, ğ·\rangle} + \frac{\alpha}{2} * |\theta-\theta^{t-1}\|^2$$

- $L_{\text{task}}$: standard cross-entropy loss on local batch $b$.
- $-\langle ğ·_k^{t}, \theta \rangle$: linear correction term using the client-specific state $h_k^t$.
- $\frac{\alpha}{2}\|\theta-\theta^{t}\|^2$: proximal term keeping the local model close to the global model $\theta^t$.

**Optimizer:** SGD with `momentum=0.9`, `weight_decay=5e-4`.

**Client state update (after local training):**

$$
g_k^{t} = g_k^{t-1} - \alpha(\theta_k^{t}-\theta^{t-1})
$$

where $\theta_k^{t+1}$ is the client model after local training and $\theta^{t}$ is the global model received at the start of round $t$.

â¸»

2) Server-side Aggregation (fl/server.py)

The server maintains a global correction state $h$ and updates the global model using a corrected averaging scheme.

(a) Server state $h$ update:
$$h^{t} = h^{t-1} - \alpha \cdot \frac{1}{m}\sum_{k\in P_i}(\theta_k^{t}-\theta^{t-1})$$<br>
	â€¢	$m$: Number of all clients<br>
	â€¢	The server state $$h$$ accumulates the average drift $$(\theta_k^{t}-\theta^{t-1})$$ across every participating clients.

(b) Global model update
For learnable parameters (weights/bias):

$$\\overline{\theta^{t}} = \frac{1}{P}\sum_{k\in P_i}\theta_k^{t}$$

$$\theta^t = \\overline{\theta^{t}} - \frac{1}{\alpha}h^{t}$$

For BatchNorm buffers (e.g., running_mean, running_var, num_batches_tracked):

$$\theta^{t} = \\overline{\theta^{t}}$$

BatchNorm buffers are aggregated by simple averaging (no FedDyn correction).

## Expected Output

Each round prints evaluation results like:
```bash
=== Evaluate global model 1 Round ===
[01] acc=XX.XX%, loss=Y.YYYYYY
```

With data_set="cifar10", num_clients=100, client_frac=0.25, local_epochs=5, batch_size=50, lr=1e-2, rounds=200, partition="niid", alpha=0.4, lr_patience=10, min_lr=1e-5:
<br>83 Round ACC=60.65%, loss=1.122256
<br>96 Round ACC=63.43%, loss=1.039685
<br>106 Round ACC=65.97%, loss=1.004173
<br>117 Round ACC=67.29%, loss=0.951618
<br>134 Round ACC=69.24%, loss=0.933948
<br>145 Round ACC=70.63%, loss=0.875592
<br>159 Round ACC=72.41%, loss=0.816083
<br>167 Round ACC=73.91%, loss=0.774350
<br>189 Round ACC=74.31%, loss=0.742489
<br>200 Round ACC=75.38%, loss=0.723625



